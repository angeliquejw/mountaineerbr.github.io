<article class="h-entry">


<!-- HEADER: h1=POST/PAGE TITLE ; time=TIMESTAMPS -->
<header>
	<h1 class="p-name" id="8">#8 - Good References, a Structure to Climb</h1>
	<time class="dt-published" datetime="2020-09-13">13/sep/2020</time>
<nav><a href="8/">[stand-alone]</a></nav>
	
	<br>
</header>


<!-- <div lang="pt" class="p-summary"></div><br> -->


<p>
Google has got a nice feature for defining a search date range.
I always use that for checking papers, articles and
writings in general.
Older papers are usually
better written and more thoughtful.
</p>

<p>
Some general problems become bolder as telecommunication
technology evolves. Communication and data publishing
changed dramatically, in such a way it is reaches a bigger proportion
of people in less time.
It may be appropriately to say a more fluid mode as opposed
to crystallise thoughts or rationales. Perhaps that 
would be called a more
<cite>fluid reality</cite> by Zygmunt Bauman..
</p>

<p>
To publishing an article on the internet, if one has got
some basic connections,
writing a piece and publishing that can be an almost immediate event.
</p>


<p>
Even unthoughtful one-liners can mess up general opinion. Take
Brazil's
<a href="https://twitter.com/jairbolsonaro">president Bolsonaro</a>,
whose sons publish  a lot of obscenities
in his name
and in the name of the Republic at Twitter.
</p>

<p>
That is how people are getting used to ever more, writing very short
text. Incomplete text should be called note and as such a collection
of notes are
not organised very much, by definition.
</p>

<p>
Also, size of a text does not mean it is better or worse than
a shorter text, although usually the shorter the harder to
understand.
</p>

<p>
There is too much of the same ideas, ever poorer modification
of existing bases for some unhelpful sophistication of one own
creativity.
</p>

<p>
That may not be a new problem, however that is for certain more common
now quantitatively than before, when a researcher wants to
conform to general opinion, fearing cuts in research budgets
or even salary.
An overflow of limits means the paper may be under serious
methodological problems when that suffices to say
there is <q>consensus</q>
and one's research confirms consensus.
<br>
Consensus should not be more important than a very well defined and
rational function, which leverages logical deduction
of further general aspects.
</p>

<p>
I reckon Einstein's genius may be
in great part due to the fact
of the environment he was brought up in,
and also because of his acknowledgement
and decision of
developing on top of very important
primitives defined by other scientists.
Synthesis is harder than analysis,
one needs a general understanding of
the overall picture and be able to
remove noise from what is really important.
</p>


<p>
I am not sure it is healthy to long to be like
Einstein. Francis Crick and Ken Thompson would
agree. Ken would probably also say to 
just do your own thing, no need to have got 
bigger perspectives
than what is feasible at the time.
</p>

<hr>
<p>
I fear this post has developed into something
else than the title may strictly suggest.
Indeed writing about Einstein made me
question what are my objectives with this
website and my youtube channel, anyways?
Too much thinking, I will just leave it at that for now.
</p>

<hr>
<p>
News about the website. I changed website structure
a little more. There are two important directories
in the website structure which are the graphics <i>'gfx'</i>
and resources <i>'res'</i> directories. The res directory will
hold anything that is not graphical, such as audio
or text, although PDFs could arguably be placed
in the gfx directory, too.
</p>

<p>
A robots.txt file was added to the home page directory.
It has not got much, of importance only a pointer to a
sitemap file.
</p>

<p>
I am using two scripts from Poor Man's Webmaster Tools
to make a <i>sitemap.txt</i> and a <i>sitemap.html</i> files.
While I will soon link the sitemap.html to visitors
in the home page, Google, Bing, Yahoo! Search, DuckDuckGo
and other engines will actually prefer to read
a <em>sitemap.xml</em> file, because it can hold some
information about the links, such as last update time,
update frequency and priority (this latter is not currently
consumed by Google bots as explicitly said in Google's website).
</p>

<p>
It was not much hard to make the third sitemap script
which generates a xml file last night, although it took
me approximately 2-3 hours to write it.. Here is a
<a href="res/script6.html">static copy of the script</a>.
Although I will be improving it over time, it may
serve as <em>an example</em> for some other person
who reads this here.
</p>

<p>
The <strong>sitemap.xml</strong>
file should actually be uploaded to these search engines
(they have got a form for that), but I reckon if you are
patient, you can just add the sitemap pointer to the robots.txt
and the robots will eventually reach that.
</p>

</article>
